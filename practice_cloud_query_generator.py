# -*- coding: utf-8 -*-
"""Practice-Cloud-Query-Generator

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wTZXsLPGKiHZR84q5kQ0xSL8xoyuIuzm
"""

# accept user input ex. How many users are there?
!pip install openai

from google.colab import auth
auth.authenticate_user()

print('Authenticated')

from google.cloud import bigquery
# Define your project ID and dataset ID
dataset_id = 'ayla_demo_data'
project_id = 'my-project-ayla-demo'
BigQclient = bigquery.Client(project=project_id)

import openai
from openai import OpenAI
import pandas as pd

import os
os.environ["OPENAI_API_KEY"] = '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'

OPENAI_API_KEY = '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'
client = OpenAI()

# take in additional scheme details ex. scheme of the user table

# generate sql query from user input using openai ex. select * from user


# get data from the database

# hey i need to write a function that will take in a question and schema and give me a sql query


def sql_query(question, schema):
    prompt = f"Given the following schema:\n{schema}\nGenerate a SQL query that answers the following question:\n{question}"
    print(prompt)
    # now we are having openai generate a response to the prompt
    query = invoke_chatgpt(prompt)
    return query
    # call function that will invoke chatgpt


def invoke_chatgpt(prompt):
    completion = client.chat.completions.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": "You are a SQL generator, create a simple query without additional inferrations"},
            {"role": "user", "content": prompt}
        ]
    )
    message = completion.choices[0].message
    message_content = message.content
    message_role = message.role
    print(message)
    print(message_content)
    print(message_role)
    return message_content

# get user input such as "How many users are there?

#new function that takes the sql query previously outputted and applies it to the cloud database

def sql_data_output(final_query):

  final_response = " "

  # get data from the database
  final_response = BigQclient.query(final_query)
  print(final_response)

  return final_response

def sql_data(sql_data):
  arr_sql_data = []
  for i in sql_data.result():
    #arr.append(i)
    print(i)
  return arr_sql_data

def construct_sql_query(base_query, stringA, stringB):
    # Split the base_query to insert the schema and project
    parts = base_query.split(' ')
    if len(parts) >= 4 and parts[0].lower() == 'select' and parts[2].lower() == 'from':
        table = parts[3]
        new_table_ref = f"{stringA}.{stringB}.{table}"
        parts[3] = new_table_ref
        return ' '.join(parts)
    else:
        raise ValueError("Invalid base query format. Expected format: 'SELECT * FROM table'")

# Example usage
#base_query = "SELECT * FROM table"
#stringA = "project"
#stringB = "dataset"
#result = construct_sql_query("SELECT * FROM table", "stringA", "stringB")
#print(result)  # Output: SELECT * FROM project.dataset.table

question = input("Enter your question: ")

schema = """
Table:
user (UserID INTEGER PRIMARY KEY, Name TEXT NOT NULL, Address TEXT NOT NULL)
"""
print(schema)

print(question)

# takes in question and schema to give sql query ex (How many users, users: Name, Address)
raw_query = sql_query(question, schema)

new_query = construct_sql_query(raw_query, project_id, dataset_id )
print(new_query)
# takes in the sql query to then get data from the database
sql_data = sql_data_output(new_query)

print(sql_data)
# runs through the queryjob and puts the data into an array
final_output = sql_final_data(sql_data)
#